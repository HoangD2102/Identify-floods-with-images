{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-05T06:16:11.799365Z","iopub.status.busy":"2023-10-05T06:16:11.798909Z","iopub.status.idle":"2023-10-05T06:16:20.985395Z","shell.execute_reply":"2023-10-05T06:16:20.984462Z","shell.execute_reply.started":"2023-10-05T06:16:11.799337Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["import pandas as pd\n","import os\n","import numpy as np\n","import cv2 \n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":20,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2023-10-05T06:16:20.990561Z","iopub.status.busy":"2023-10-05T06:16:20.987115Z","iopub.status.idle":"2023-10-05T06:16:20.995465Z","shell.execute_reply":"2023-10-05T06:16:20.994616Z","shell.execute_reply.started":"2023-10-05T06:16:20.990520Z"},"trusted":true},"outputs":[],"source":["train_path = 'devset_images/devset_images'\n","test_path = 'testset_images/testset_images'\n","label_file_path = 'devset_images_gt.csv'"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:16:20.997576Z","iopub.status.busy":"2023-10-05T06:16:20.996630Z","iopub.status.idle":"2023-10-05T06:17:41.677582Z","shell.execute_reply":"2023-10-05T06:17:41.676597Z","shell.execute_reply.started":"2023-10-05T06:16:20.997544Z"},"trusted":true},"outputs":[],"source":["img_width, img_height = 224, 224\n","batch_size = 32\n","epochs = 20\n","\n","# Load labels from CSV file\n","labels_df = pd.read_csv(label_file_path)\n","train_labels = labels_df['label'].values\n","\n","# Load training images\n","train_images = []\n","train_ids = labels_df['id'].astype(str).values\n","\n","for image_id in train_ids:\n","    image_path = None\n","    for extension in ['.jpg', '.png', '.gif']:\n","        temp_path = os.path.join(train_path, f\"{image_id}{extension}\")\n","        if os.path.exists(temp_path):\n","            image_path = temp_path\n","            break\n","\n","    if image_path is not None:\n","        img = load_img(image_path, target_size=(img_width, img_height))\n","        \n","     # Preprocessing images\n","        img = cv2.imread(image_path)\n","        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img,(img_width, img_height))\n","        img = img.astype('float32') / 255.0\n","        \n","        img_array = img_to_array(img)\n","        #train_images = np.append(train_images, img)\n","        train_images.append(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:17:41.680681Z","iopub.status.busy":"2023-10-05T06:17:41.680014Z","iopub.status.idle":"2023-10-05T06:17:43.891125Z","shell.execute_reply":"2023-10-05T06:17:43.890197Z","shell.execute_reply.started":"2023-10-05T06:17:41.680647Z"},"trusted":true},"outputs":[],"source":["train_images = np.array(train_images)\n","train_labels = np.array(train_labels)\n","\n","# Split the training data into training and validation sets\n","train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:17:43.893190Z","iopub.status.busy":"2023-10-05T06:17:43.892381Z","iopub.status.idle":"2023-10-05T06:17:43.897799Z","shell.execute_reply":"2023-10-05T06:17:43.896969Z","shell.execute_reply.started":"2023-10-05T06:17:43.893157Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.applications import VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:17:43.899854Z","iopub.status.busy":"2023-10-05T06:17:43.899290Z","iopub.status.idle":"2023-10-05T06:17:47.234463Z","shell.execute_reply":"2023-10-05T06:17:47.233508Z","shell.execute_reply.started":"2023-10-05T06:17:43.899823Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n"]}],"source":["vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:17:47.235944Z","iopub.status.busy":"2023-10-05T06:17:47.235630Z","iopub.status.idle":"2023-10-05T06:17:47.240485Z","shell.execute_reply":"2023-10-05T06:17:47.239504Z","shell.execute_reply.started":"2023-10-05T06:17:47.235915Z"},"trusted":true},"outputs":[],"source":["for layer in vgg16.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:17:47.243026Z","iopub.status.busy":"2023-10-05T06:17:47.242025Z","iopub.status.idle":"2023-10-05T06:17:47.254892Z","shell.execute_reply":"2023-10-05T06:17:47.254132Z","shell.execute_reply.started":"2023-10-05T06:17:47.242998Z"},"trusted":true},"outputs":[],"source":["# Create a data generator for data augmentation\n","data_generator = ImageDataGenerator(rotation_range=20, width_shift_range=0.1, height_shift_range=0.1,\n","                                    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:17:47.256753Z","iopub.status.busy":"2023-10-05T06:17:47.256451Z","iopub.status.idle":"2023-10-05T06:36:08.966938Z","shell.execute_reply":"2023-10-05T06:36:08.965944Z","shell.execute_reply.started":"2023-10-05T06:17:47.256726Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","132/132 [==============================] - 56s 351ms/step - loss: 0.5737 - accuracy: 0.7692 - val_loss: 0.3928 - val_accuracy: 0.8258\n","Epoch 2/20\n","132/132 [==============================] - 46s 344ms/step - loss: 0.3864 - accuracy: 0.8232 - val_loss: 0.3690 - val_accuracy: 0.8456\n","Epoch 3/20\n","132/132 [==============================] - 47s 353ms/step - loss: 0.3487 - accuracy: 0.8456 - val_loss: 0.3517 - val_accuracy: 0.8456\n","Epoch 4/20\n","132/132 [==============================] - 46s 351ms/step - loss: 0.3503 - accuracy: 0.8459 - val_loss: 0.3727 - val_accuracy: 0.8362\n","Epoch 5/20\n","132/132 [==============================] - 46s 350ms/step - loss: 0.3267 - accuracy: 0.8546 - val_loss: 0.3598 - val_accuracy: 0.8371\n","Epoch 6/20\n","132/132 [==============================] - 45s 339ms/step - loss: 0.3325 - accuracy: 0.8494 - val_loss: 0.3539 - val_accuracy: 0.8419\n","Epoch 7/20\n","132/132 [==============================] - 46s 347ms/step - loss: 0.3144 - accuracy: 0.8625 - val_loss: 0.3808 - val_accuracy: 0.8419\n","Epoch 8/20\n","132/132 [==============================] - 45s 343ms/step - loss: 0.3082 - accuracy: 0.8639 - val_loss: 0.3614 - val_accuracy: 0.8551\n","Epoch 9/20\n","132/132 [==============================] - 45s 341ms/step - loss: 0.3039 - accuracy: 0.8653 - val_loss: 0.3485 - val_accuracy: 0.8504\n","Epoch 10/20\n","132/132 [==============================] - 44s 336ms/step - loss: 0.2809 - accuracy: 0.8788 - val_loss: 0.3558 - val_accuracy: 0.8513\n","Epoch 11/20\n","132/132 [==============================] - 46s 346ms/step - loss: 0.2941 - accuracy: 0.8672 - val_loss: 0.3560 - val_accuracy: 0.8551\n","Epoch 12/20\n","132/132 [==============================] - 45s 341ms/step - loss: 0.2931 - accuracy: 0.8726 - val_loss: 0.3543 - val_accuracy: 0.8456\n","Epoch 13/20\n","132/132 [==============================] - 46s 348ms/step - loss: 0.2778 - accuracy: 0.8778 - val_loss: 0.3550 - val_accuracy: 0.8475\n","Epoch 14/20\n","132/132 [==============================] - 45s 343ms/step - loss: 0.2717 - accuracy: 0.8842 - val_loss: 0.3683 - val_accuracy: 0.8428\n","Epoch 15/20\n","132/132 [==============================] - 46s 351ms/step - loss: 0.2605 - accuracy: 0.8892 - val_loss: 0.3757 - val_accuracy: 0.8456\n","Epoch 16/20\n","132/132 [==============================] - 45s 340ms/step - loss: 0.2594 - accuracy: 0.8840 - val_loss: 0.3865 - val_accuracy: 0.8475\n","Epoch 17/20\n","132/132 [==============================] - 45s 341ms/step - loss: 0.2662 - accuracy: 0.8873 - val_loss: 0.3850 - val_accuracy: 0.8286\n","Epoch 18/20\n","132/132 [==============================] - 45s 345ms/step - loss: 0.2741 - accuracy: 0.8802 - val_loss: 0.3652 - val_accuracy: 0.8475\n","Epoch 19/20\n","132/132 [==============================] - 45s 342ms/step - loss: 0.2505 - accuracy: 0.8932 - val_loss: 0.3706 - val_accuracy: 0.8561\n","Epoch 20/20\n","132/132 [==============================] - 46s 352ms/step - loss: 0.2460 - accuracy: 0.8946 - val_loss: 0.4056 - val_accuracy: 0.8333\n"]}],"source":["# Build the CNN model\n","# Build a new model on top of the pre-trained layers\n","# model = Sequential()\n","# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n","# model.add(Conv2D(64, (3, 3), activation='relu'))\n","# model.add(MaxPooling2D((2, 2)))\n","# model.add(Conv2D(128, (3, 3), activation='relu'))\n","# model.add(MaxPooling2D((2, 2)))\n","# model.add(Flatten())\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","model = Sequential()\n","model.add(vgg16)\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","\n","# Train the model\n","history = model.fit(data_generator.flow(train_images, train_labels, batch_size=batch_size), \n","                    steps_per_epoch=len(train_images) // batch_size,\n","                    epochs=epochs, validation_data=(val_images, val_labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:36:08.970780Z","iopub.status.busy":"2023-10-05T06:36:08.970105Z","iopub.status.idle":"2023-10-05T06:36:36.562282Z","shell.execute_reply":"2023-10-05T06:36:36.561314Z","shell.execute_reply.started":"2023-10-05T06:36:08.970754Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["42/42 [==============================] - 4s 83ms/step\n"]}],"source":["testset = '/kaggle/input/dplfall2023test/test.csv'\n","\n","test_data = pd.read_csv(testset)\n","\n","test_ids = test_data['image_id'].astype(str).values\n","\n","test_images = []\n","predicted_labels = []\n","\n","skipped_image = []\n","\n","for image_id in test_ids:\n","    image_path = None\n","    for extension in ['.jpg', '.png', '.gif','jpeg']:\n","        temp_path = os.path.join(test_path, f\"{image_id}{extension}\")\n","        if os.path.exists(temp_path):\n","            image_path = temp_path\n","            break\n","\n","    if image_path is not None:\n","        img = load_img(image_path, target_size=(img_width, img_height))\n","        \n","     # Preprocessing images\n","        img = cv2.imread(image_path)\n","        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img,(img_width, img_height))\n","        img = img.astype('float32')\n","        \n","        img_array = img_to_array(img)\n","        #test_images = np.append(test_images, img)\n","        test_images.append(img)\n","test_images = np.array(test_images)\n","\n","# Predict label for the image\n","#prediction = model.predict(np.expand_dims(img, axis=0))\n","prediction = model.predict(test_images)\n","predicted_labels = np.round(prediction).flatten()\n","# predicted_label = int(np.round(prediction)[0])\n","# predicted_labels.append(predicted_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:36:36.564344Z","iopub.status.busy":"2023-10-05T06:36:36.563735Z","iopub.status.idle":"2023-10-05T06:36:51.453418Z","shell.execute_reply":"2023-10-05T06:36:51.452476Z","shell.execute_reply.started":"2023-10-05T06:36:36.564310Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[ WARN:0@1227.821] global loadsave.cpp:248 findDecoder imread_('/kaggle/input/dplfall2023/2023falldpl30xm/testset_images/testset_images/5847540163.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1228.714] global loadsave.cpp:248 findDecoder imread_('/kaggle/input/dplfall2023/2023falldpl30xm/testset_images/testset_images/9567943158.jpg'): can't open/read file: check file path/integrity\n"]},{"name":"stdout","output_type":"stream","text":["42/42 [==============================] - 3s 66ms/step\n","              id  label\n","0     3483809003    1.0\n","1     3712805295    0.0\n","2      379845620    0.0\n","3     7343264988    0.0\n","4     3843337492    0.0\n","...          ...    ...\n","1315  6452132743    0.0\n","1316   244899140    0.0\n","1317  3073018258    0.0\n","1318    49525361    0.0\n","1319   537780925    0.0\n","\n","[1320 rows x 2 columns]\n","Skipped Images:\n"]}],"source":["testset = '/kaggle/input/dplfall2023test/test.csv'\n","test_folder = '/kaggle/input/dplfall2023/2023falldpl30xm/testset_images/testset_images'\n","test_data = pd.read_csv(testset)\n","\n","test_ids = test_data['image_id'].astype(str).values\n","\n","test_images = []\n","predicted_labels = []\n","skipped_images = []\n","\n","for image_id in test_ids:\n","    image_path = os.path.join(test_folder, str(image_id))\n","\n","    if not any(image_path.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n","        image_path += '.jpg'\n","\n","    try:\n","        image = cv2.imread(image_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    except:\n","        image_path = image_path[:-4] + '.png'\n","        try:\n","            image = cv2.imread(image_path)\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        except:\n","            print(f\"Image not found: {image_path}\")\n","            skipped_images.append(image_id)\n","            continue\n","\n","    image = cv2.resize(image, (224, 224))\n","    image = image.astype('float32')\n","    test_images.append(image)\n","\n","test_images = np.array(test_images)\n","\n","# Predict the labels for the test images\n","predictions = model.predict(test_images)\n","predicted_labels = np.round(predictions).flatten()\n","\n","# Create a DataFrame for the predicted labels and image IDs\n","predicted_df = pd.DataFrame({'id': test_ids, 'label': predicted_labels})\n","\n","# Print the predicted DataFrame\n","print(predicted_df)\n","\n","# Print the skipped images\n","print(\"Skipped Images:\")\n","for image_id in skipped_images:\n","    print(f'Image ID: {image_id}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:36:51.455397Z","iopub.status.busy":"2023-10-05T06:36:51.455031Z","iopub.status.idle":"2023-10-05T06:36:51.464120Z","shell.execute_reply":"2023-10-05T06:36:51.462894Z","shell.execute_reply.started":"2023-10-05T06:36:51.455367Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              id  label\n","0     3483809003      1\n","1     3712805295      0\n","2      379845620      0\n","3     7343264988      0\n","4     3843337492      0\n","...          ...    ...\n","1315  6452132743      0\n","1316   244899140      0\n","1317  3073018258      0\n","1318    49525361      0\n","1319   537780925      0\n","\n","[1320 rows x 2 columns]\n"]}],"source":["# Create a DataFrame for the predicted labels and image IDs\n","predicted_df = pd.DataFrame({'id': test_ids, 'label': predicted_labels})\n","predicted_df['label'] = predicted_df['label'].astype(int)\n","\n","# Print the predicted DataFrame\n","print(predicted_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:36:51.466522Z","iopub.status.busy":"2023-10-05T06:36:51.465411Z","iopub.status.idle":"2023-10-05T06:36:51.479973Z","shell.execute_reply":"2023-10-05T06:36:51.479121Z","shell.execute_reply.started":"2023-10-05T06:36:51.466486Z"},"trusted":true},"outputs":[],"source":["predicted_df.to_csv('test4.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:36:51.482246Z","iopub.status.busy":"2023-10-05T06:36:51.481500Z","iopub.status.idle":"2023-10-05T06:36:51.489389Z","shell.execute_reply":"2023-10-05T06:36:51.488449Z","shell.execute_reply.started":"2023-10-05T06:36:51.482214Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.0\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_28/1386729578.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","  accuracy = np.mean(predicted_labels == train_labels)\n"]}],"source":["accuracy = np.mean(predicted_labels == train_labels)\n","print(f\"Test Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T06:36:51.491576Z","iopub.status.busy":"2023-10-05T06:36:51.490940Z","iopub.status.idle":"2023-10-05T06:36:51.755135Z","shell.execute_reply":"2023-10-05T06:36:51.754063Z","shell.execute_reply.started":"2023-10-05T06:36:51.491547Z"},"trusted":true},"outputs":[],"source":["# Save the trained model\n","model.save('training_model.h5')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":4}
